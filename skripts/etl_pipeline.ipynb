{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ETL Pipeline\n\nThis notebook cleans the raw data and creates an hourly aggregated `masterdata_2024.csv`."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import pandas as pd\nimport glob, os\nfrom dotenv import load_dotenv\nload_dotenv()\n\nPATH_DATA = os.getenv('path_to_data')\nPATH_MASTER = os.getenv('path_to_master')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Weather data"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "def fix_dates(df):\n    df['DATUM'] = df['MESS_DATUM'].astype(str)\n    df['DATUM'] = pd.to_datetime(df['DATUM'].str.slice(0, 10), format='%Y%m%d%H')\n    df.set_index('DATUM', inplace=True)\n    return df\n\ndef rename_columns(df):\n    renames = {}  # add column mappings if necessary\n    return df.rename(columns=renames)\n\ndef remove_duplicate_columns(df):\n    return df.drop(columns=['eor', 'STATIONS_ID', 'MESS_DATUM'], errors='ignore')\n\ndef clean_weather_files():\n    for file in glob.glob(os.path.join(PATH_DATA, 'schnarrenberg_dwd*.csv')):\n        df = pd.read_csv(file, delimiter=';')\n        df = fix_dates(df)\n        df = rename_columns(df)\n        out = os.path.join(PATH_DATA, f'clean_{os.path.basename(file)}')\n        df.to_csv(out)\n\ndef aggregate_weather():\n    files = glob.glob(os.path.join(PATH_DATA, 'clean_schnarrenberg_dwd*.csv'))\n    date_range = pd.date_range('2023-01-01', '2025-12-31 23:00:00', freq='h')\n    df = pd.DataFrame(index=date_range)\n    for file in files:\n        df_new = pd.read_csv(file)\n        df_new = remove_duplicate_columns(df_new)\n        df_new['DATUM'] = pd.to_datetime(df_new['DATUM'])\n        df_new.set_index('DATUM', inplace=True)\n        df = df.merge(df_new, left_index=True, right_index=True, how='left', suffixes=('', '_y'))\n    df.dropna(how='all', inplace=True)\n    df.to_csv(os.path.join(PATH_DATA, 'clean_wetter_komplett.csv'))\n    return df",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Measurement data"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "def clean_measurements():\n    df = pd.read_csv(os.path.join(PATH_MASTER, 'messungen_2024.csv'), delimiter=';').T\n    df.columns = df.iloc[0]\n    df = df.iloc[1:].copy()\n    df.columns = ['zeit', 'ecoli', 'entro', 'pos_neg']\n    df.index.rename('DATUM', inplace=True)\n    for col in ['ecoli', 'entro']:\n        df[col] = df[col].str.replace('>800', '8000').str.replace('>80', '8000').str.replace('>', '').astype(float)\n    df.reset_index(inplace=True)\n    month_map = {'Jan': '01.', 'Febr': '02.', 'Mär': '03.', 'Apr': '04.', 'Mai': '05.', 'Jun': '06.', 'Jul': '07.', 'Aug': '08.', 'Sep': '09.', 'Okt': '10.', 'Nov': '11.', 'Dez': '12.'}\n    for k,v in month_map.items():\n        df['DATUM'] = df['DATUM'].str.replace(k, v)\n    def fill_year(d):\n        return d if d.endswith('24') else d + ' 24'\n    def fix_date(d):\n        parts = d.split(' ')\n        return '20'+parts[-1]+'-'+parts[1][:-1]+'-'+parts[0][:-1]\n    def add_time(date, time):\n        hour = time.str.split(':').str[0]\n        return date + ' ' + hour + ':00:00'\n    df['DATUM'] = df['DATUM'].apply(fill_year).apply(fix_date)\n    df['DATUM'] = add_time(df['DATUM'], df['zeit'])\n    df['DATUM'] = pd.to_datetime(df['DATUM']).dt.round('h')\n    df.set_index('DATUM', inplace=True)\n    df.to_csv(os.path.join(PATH_MASTER, 'messungen_clean_2024.csv'))\n    return df",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Additional water temperature"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "def clean_hofen_temp(master_df):\n    df = pd.read_csv(os.path.join(PATH_DATA, 'hofen_wassertemp.csv'), delimiter=';')\n    df['Datum'] = pd.to_datetime(df['Datum'], format='%d.%m.%Y')\n    df = df[df['Datum'] > pd.to_datetime('2024-01-01')]\n    df = df[['Datum', 'Tagesmittelwert']].set_index('Datum')\n    df['Tagesmittelwert'] = pd.to_numeric(df['Tagesmittelwert'], errors='coerce')\n    df.rename(columns={'Tagesmittelwert': 'Wassertemperatur Hofen'}, inplace=True)\n    df = df.resample('h').bfill().ffill()\n    return master_df.merge(df, left_index=True, right_index=True, how='left')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Combine all data"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "def create_masterdata():\n    weather = aggregate_weather()\n    messungen = clean_measurements()\n    df = weather.merge(messungen, left_index=True, right_index=True, how=\"left\")\n    # LUBW-Daten laden und verarbeiten\n    df_lubw_raw = pd.read_csv(\n        os.path.join(PATH_DATA, \"messwerte_lubw.csv\"),\n        delimiter=\";\",\n        parse_dates=[\"Datum\"],\n        dayfirst=True,\n    )\n    # Relevante Spalten extrahieren\n    df_lubw = df_lubw_raw[[\"Messstation\", \"Gewässer\", \"Parameter\", \"Datum\", \"Tagesmittelwert\"]]\n    # Zahlen konvertieren (Komma → Punkt, \"-\" → NaN)\n    df_lubw[\"Tagesmittelwert\"] = df_lubw[\"Tagesmittelwert\"].str.replace(\",\", \".\")\n    df_lubw[\"Tagesmittelwert\"] = pd.to_numeric(df_lubw[\"Tagesmittelwert\"], errors=\"coerce\")\n    # Kürzel erstellen z.B. We_Ne_Temperatur\n    df_lubw[\"Kürzel\"] = (\n        df_lubw[\"Messstation\"].str[:2].str.capitalize()\n        + \"_\"\n        + df_lubw[\"Gewässer\"].str[:2].str.capitalize()\n        + \"_\"\n        + df_lubw[\"Parameter\"]\n            .str.replace(\"bei .*\", \"\", regex=True)\n            .str.replace(\" \", \"\")\n            .str.replace(\"ä\", \"ae\")\n            .str.replace(\"ö\", \"oe\")\n            .str.replace(\"ü\", \"ue\")\n            .str.replace(\"ß\", \"ss\")\n    )\n    # Pivotieren: Datum als Index, Parameter als Spalten\n    df_lubw_pivot = df_lubw.pivot(index=\"Datum\", columns=\"Kürzel\", values=\"Tagesmittelwert\")\n    # Resample auf 1h und auffüllen\n    df_lubw_hourly = df_lubw_pivot.resample(\"1h\").ffill()\n    # In Masterdaten integrieren\n    df = df.merge(df_lubw_hourly, left_index=True, right_index=True, how=\"left\")\n    df = clean_hofen_temp(df)\n    df.index.name = \"zeit\"\n    df.to_csv(os.path.join(PATH_MASTER, \"masterdata_2024.csv\"))\n    return df",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Run the ETL pipeline\ncreate_masterdata()",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
