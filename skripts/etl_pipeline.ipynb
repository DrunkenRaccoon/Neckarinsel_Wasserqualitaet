{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ETL Pipeline\n\nThis notebook cleans the raw data and writes an hourly aggregated `masterdata_<YEAR>.csv` where `<YEAR>` corresponds to the data folder."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import pandas as pd\nimport glob, os, re\nfrom dotenv import load_dotenv\nload_dotenv()\n\nPATH_DATA = os.getenv('path_to_data')\nPATH_MASTER = os.getenv('path_to_master')\nmatch = re.search(r'(\\d{4})', PATH_DATA or '')\nYEAR = os.getenv('YEAR', match.group(1) if match else '2024')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Weather data"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "def fix_dates(df):\n    df['DATUM'] = df['MESS_DATUM'].astype(str)\n    df['DATUM'] = pd.to_datetime(df['DATUM'].str.slice(0, 10), format='%Y%m%d%H')\n    df.set_index('DATUM', inplace=True)\n    return df\n\ndef rename_columns(df):\n    renames = {}  # add column mappings if necessary\n    return df.rename(columns=renames)\n\ndef remove_duplicate_columns(df):\n    return df.drop(columns=['eor', 'STATIONS_ID', 'MESS_DATUM'], errors='ignore')\n\ndef clean_weather_files():\n    for file in glob.glob(os.path.join(PATH_DATA, 'schnarrenberg_dwd*.csv')):\n        df = pd.read_csv(file, delimiter=';')\n        df = fix_dates(df)\n        df = rename_columns(df)\n        out = os.path.join(PATH_DATA, f'clean_{os.path.basename(file)}')\n        df.to_csv(out)\n\ndef aggregate_weather():\n    files = glob.glob(os.path.join(PATH_DATA, 'clean_schnarrenberg_dwd*.csv'))\n    start = f'{YEAR}-01-01'\n    end = f'{YEAR}-12-31 23:00:00'\n    date_range = pd.date_range(start, end, freq='h')\n    df = pd.DataFrame(index=date_range)\n    for file in files:\n        df_new = pd.read_csv(file)\n        df_new = remove_duplicate_columns(df_new)\n        df_new['DATUM'] = pd.to_datetime(df_new['DATUM'])\n        df_new.set_index('DATUM', inplace=True)\n        df = df.merge(df_new, left_index=True, right_index=True, how='left', suffixes=('', '_y'))\n    df.dropna(how='all', inplace=True)\n    df.to_csv(os.path.join(PATH_DATA, 'clean_wetter_komplett.csv'))\n    return df",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Measurement data"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "def clean_measurements():\n    df = pd.read_csv(os.path.join(PATH_MASTER, f'messungen_{YEAR}.csv'), delimiter=';').T\n    df.columns = df.iloc[0]\n    df = df.iloc[1:].copy()\n    df.columns = ['zeit','ecoli','entro','pos_neg']\n    df.index.rename('DATUM', inplace=True)\n    for col in ['ecoli','entro']:\n        df[col] = df[col].str.replace('>800','8000').str.replace('>80','8000').str.replace('>','').astype(float)\n    df.reset_index(inplace=True)\n    month_map={'Jan':'01.','Febr':'02.','M\u00e4r':'03.','Apr':'04.','Mai':'05.','Jun':'06.','Jul':'07.','Aug':'08.','Sep':'09.','Okt':'10.','Nov':'11.','Dez':'12.'}\n    for k,v in month_map.items():\n        df['DATUM'] = df['DATUM'].str.replace(k,v)\n    def fill_year(d):\n        return d if d.endswith(str(YEAR)[-2:]) else d + ' ' + str(YEAR)[-2:]\n    def fix_date(d):\n        parts=d.split(' ')\n        return '20'+parts[-1]+'-'+parts[1][:-1]+'-'+parts[0][:-1]\n    def add_time(date,time):\n        hour=time.str.split(':').str[0]\n        return date+' '+hour+':00:00'\n    df['DATUM']=df['DATUM'].apply(fill_year).apply(fix_date)\n    df['DATUM']=add_time(df['DATUM'],df['zeit'])\n    df['DATUM']=pd.to_datetime(df['DATUM']).dt.round('h')\n    df.set_index('DATUM', inplace=True)\n    df.to_csv(os.path.join(PATH_MASTER, f'messungen_clean_{YEAR}.csv'))\n    return df",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Additional water temperature"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "def clean_hofen_temp(master_df):\n    df = pd.read_csv(os.path.join(PATH_DATA, 'hofen_wassertemp.csv'), delimiter=';')\n    df['Datum'] = pd.to_datetime(df['Datum'], format='%d.%m.%Y')\n    df = df[df['Datum'] > pd.to_datetime(f'{YEAR}-01-01')]\n    df = df[['Datum', 'Tagesmittelwert']].set_index('Datum')\n    df['Tagesmittelwert'] = pd.to_numeric(df['Tagesmittelwert'], errors='coerce')\n    df.rename(columns={'Tagesmittelwert': 'Wassertemperatur Hofen'}, inplace=True)\n    df = df.resample('h').bfill().ffill()\n    return master_df.merge(df, left_index=True, right_index=True, how='left')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Combine all data"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "def create_masterdata():\n    weather = aggregate_weather()\n    messungen = clean_measurements()\n    df = weather.merge(messungen, left_index=True, right_index=True, how='left')\n    df_wendlingen = pd.read_csv(os.path.join(PATH_DATA, 'wendlingen_messwerte.csv'), delimiter=';', parse_dates=True, index_col=0)\n    df_wendlingen = df_wendlingen.pivot(index='Datum', columns='Parameter', values='Tagesmittelwert')\n    df_wendlingen.index = pd.to_datetime(df_wendlingen.index, format='%d.%m.%Y')\n    df_wendlingen = df_wendlingen.resample('1h').first().ffill()\n    for col in df_wendlingen.columns:\n        df_wendlingen[col] = pd.to_numeric(df_wendlingen[col].str.replace(',', '.'), errors='coerce')\n    df = df.merge(df_wendlingen, left_index=True, right_index=True, how='left')\n    df = clean_hofen_temp(df)\n    df = df.loc[f'{YEAR}']\n    df.index.name = 'zeit'\n    df.to_csv(os.path.join(PATH_MASTER, f'masterdata_{YEAR}.csv'))\n    return df",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Run the ETL pipeline\ncreate_masterdata()",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
